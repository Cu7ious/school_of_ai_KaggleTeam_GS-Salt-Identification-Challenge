{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "School of Ai Colab V0-1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Fede2000/school_of_ai_KaggleTeam_GS-Salt-Identification-Challenge/blob/master/colab/School_of_Ai_Colab_V0_1.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "gMf633aN0uLS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3950bed6-aced-4dba-e46f-fd4cced65300"
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle competitions download -c tgs-salt-identification-challenge\n",
        "\n",
        "!mkdir train\n",
        "!mkdir test\n",
        "\n",
        "%cd train\n",
        "!unzip ../train.zip\n",
        "%cd ./test\n",
        "%ls\n",
        "!unzip ../test.zip\n",
        "#%cd ../\n",
        "'''\n",
        "\n",
        "%ls\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "depths.csv   sample_submission.csv  test.zip  train.csv\n",
            "kaggle.json  \u001b[0m\u001b[01;34mtest\u001b[0m/                  \u001b[01;34mtrain\u001b[0m/    train.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Hq8L_ShW2kqL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa94754b-2ce0-4e6b-919b-650efb15a612"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "wdmybzHF3-TG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data processing"
      ]
    },
    {
      "metadata": {
        "id": "W-H_chT90wMp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SaltParser(object):\n",
        "\n",
        "    \"\"\"\n",
        "    Parser for Salt Competition.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_src='../input/',\n",
        "                 image_size=(128, 128),\n",
        "                 pad_images=False,\n",
        "                 grayscale=True,\n",
        "                 load_test_data=True):\n",
        "\n",
        "        self.data_src = data_src\n",
        "        self.image_size = image_size\n",
        "        self.pad_images = pad_images\n",
        "        self.grayscale = grayscale\n",
        "        self.load_test_data = load_test_data\n",
        "\n",
        "        self.train_df = None\n",
        "        self.test_df = None\n",
        "        self.padding_pixels = None\n",
        "\n",
        "        self.X_train = []\n",
        "        self.y_train = []\n",
        "        self.X_test = []\n",
        "\n",
        "        self.orig_image_size = (101, 101)\n",
        "        \n",
        "        \"\"\"\n",
        "        # Arguments:\n",
        "        \n",
        "            data_src: directory containing data\n",
        "            image_size: tuple specifying final image size\n",
        "            pad_images: whether images should be padded or resized\n",
        "            grayscale: whether to load images as grayscale\n",
        "            load_test_data: whether to load test data\n",
        "            \n",
        "        \"\"\"\n",
        "\n",
        "    def initialize_data(self):\n",
        "        \n",
        "        \"\"\"\n",
        "        Initialize processing by loading .csv files.\n",
        "        \"\"\"\n",
        "\n",
        "        train_df = pd.read_csv('{}train.csv'.format(self.data_src),\n",
        "                               usecols=[0], index_col='id')\n",
        "        depths_df = pd.read_csv('{}depths.csv'.format(self.data_src),\n",
        "                                index_col='id')\n",
        "\n",
        "        self.train_df = train_df.join(depths_df)\n",
        "        self.test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
        "\n",
        "        return\n",
        "\n",
        "    def load_data(self):\n",
        "        \n",
        "        \"\"\"\n",
        "        Load images and masks from training set.\n",
        "        \n",
        "        # Returns:\n",
        "            self.X_train: np.array of training images\n",
        "            self.y_train: np.array of training masks\n",
        "            self.X_test: np.array of test images\n",
        "        \"\"\"\n",
        "\n",
        "        print('Loading training set.')\n",
        "        # Loop over ids in train_df\n",
        "        for i in tqdm(self.train_df.index):\n",
        "            # Load image and mask according to ID\n",
        "            img_src = '{}train/images/{}.png'.format(self.data_src, i)\n",
        "            mask_src = '{}train/masks/{}.png'.format(self.data_src, i)\n",
        "            # Specify if image should be loaded in grayscale.\n",
        "            if self.grayscale:\n",
        "                img_temp = cv2.imread(img_src, 0)\n",
        "            else:\n",
        "                img_temp = cv2.imread(img_src)\n",
        "            # Load mask\n",
        "            mask_temp = cv2.imread(mask_src, 0)\n",
        "            # Resize or pad image and mask\n",
        "            if self.orig_image_size != self.image_size:\n",
        "                if self.pad_images:\n",
        "                    img_temp = self.__pad_image(img_temp)\n",
        "                    mask_temp = self.__pad_image(mask_temp)\n",
        "                else:\n",
        "                    img_temp = cv2.resize(img_temp, self.image_size)\n",
        "                    mask_temp = cv2.resize(mask_temp, self.image_size)\n",
        "            # Append processed image and mask\n",
        "            self.X_train.append(img_temp)\n",
        "            self.y_train.append(mask_temp)\n",
        "\n",
        "        # Transform into arrays\n",
        "        self.X_train = np.asarray(self.X_train)\n",
        "        self.y_train = np.asarray(self.y_train)\n",
        "        # If images were loaded as grayscale, they are loaded as (HxW) arrays\n",
        "        # Dimensions must be expanded for the model to be trained.\n",
        "        if self.grayscale:\n",
        "            self.X_train = np.expand_dims(self.X_train, -1)\n",
        "        # Mask must be expanded obligatorily, as they are 1-channel by default.\n",
        "        self.y_train = np.expand_dims(self.y_train, -1)\n",
        "\n",
        "        # Output information about training set.\n",
        "        print('Training set ready.')\n",
        "        print('X_train shape: {}'.format(self.X_train.shape))\n",
        "        print('y_train shape: {}'.format(self.y_train.shape))\n",
        "        print('X_train - min: {}, max: {}'.format(\n",
        "            np.min(self.X_train), np.max(self.X_train)))\n",
        "        print('y_train - min: {}, max: {}'.format(\n",
        "            np.min(self.y_train), np.max(self.y_train)))\n",
        "\n",
        "        # Load test data.\n",
        "        # Perform similar steps to the training processing part,\n",
        "        # but there are no masks to be loaded.\n",
        "        if self.load_test_data:\n",
        "            print('Loading test set.')\n",
        "            for i in tqdm(self.test_df.index):\n",
        "                img_src = '{}test/images/{}.png'.format(self.data_src, i)\n",
        "                if self.grayscale:\n",
        "                    img_temp = cv2.imread(img_src, 0)\n",
        "                else:\n",
        "                    img_temp = cv2.imread(img_src)\n",
        "                if self.orig_image_size != self.image_size:\n",
        "                    if self.pad_images:\n",
        "                        img_temp = self.__pad_image(img_temp)\n",
        "                    else:\n",
        "                        img_temp = cv2.resize(img_temp, self.image_size)\n",
        "                self.X_test.append(img_temp)\n",
        "\n",
        "            self.X_test = np.asarray(self.X_test)\n",
        "            if self.grayscale:\n",
        "                self.X_test = np.expand_dims(self.X_test, -1)\n",
        "\n",
        "            print('Test set ready.')\n",
        "            print('X_test shape: {}'.format(self.X_test.shape))\n",
        "            print('X_test - min: {}, max: {}'.format(\n",
        "                np.min(self.X_test), np.max(self.X_test)))\n",
        "\n",
        "            return self.X_train, self.y_train, self.X_test\n",
        "\n",
        "        return self.X_train, self.y_train\n",
        "\n",
        "    def compute_coverage(self):\n",
        "        \n",
        "        \"\"\"\n",
        "        Compute salt coverage of each mask. This will serve as a basis for \n",
        "        stratified split between training and validation sets.\n",
        "        \n",
        "        # Returns:\n",
        "            self.train_df: training DF containing coverage information.\n",
        "        \"\"\"\n",
        "\n",
        "        print('Compute mask coverage for each observation.')\n",
        "\n",
        "        def cov_to_class(val):\n",
        "            for i in range(0, 11):\n",
        "                if val * 10 <= i:\n",
        "                    return i\n",
        "\n",
        "        # Output percentage of area covered by class\n",
        "        self.train_df['coverage'] = np.mean(self.y_train / 255., axis=(1, 2))\n",
        "        # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
        "        # because each coverage will occur only once.\n",
        "        self.train_df['coverage_class'] = self.train_df.coverage.map(\n",
        "            cov_to_class)\n",
        "\n",
        "        return self.train_df\n",
        "\n",
        "    def predictions_rle_encode(self,\n",
        "                               y_pred_test,\n",
        "                               confidence_threshold_best):\n",
        "        \n",
        "        \"\"\"\n",
        "        Run Length Encoding of predictions.\n",
        "        This is needed for submission output.\n",
        "        \n",
        "        # Arguments:\n",
        "            y_pred_test: model predictions\n",
        "            confidence_threshold_best: confidence threshold, according to which\n",
        "                masks are set to 1/0.\n",
        "        # Returns:\n",
        "            y_test_pred_rle: RLEncoded predictions.\n",
        "        \"\"\"\n",
        "\n",
        "        # If images were padded, this padding must now be removed.\n",
        "        # Otherwise encoding method will fail to properly encode predictions and\n",
        "        # score will be bad.\n",
        "        if self.pad_images:\n",
        "            print('Remove padding from images.')\n",
        "            y_min_pad, y_max_pad, x_min_pad, x_max_pad = self.padding_pixels[\n",
        "                0], self.padding_pixels[1], self.padding_pixels[2], self.padding_pixels[3]\n",
        "            y_pred_test = y_pred_test[:, y_min_pad:-\n",
        "                                      y_max_pad, x_min_pad:-x_max_pad, 0]\n",
        "            \n",
        "        # Situation is similar for previously resized images.\n",
        "        # They must be resized again to their original size before encoding.\n",
        "        else:\n",
        "            y_pred_test = np.asarray([cv2.resize(x, self.orig_image_size)\n",
        "                                      for x in y_pred_test])\n",
        "\n",
        "        assert y_pred_test.shape == (18000, 101, 101), '\\\n",
        "        Test predictions shape must be equal to (18000, 101, 101).'\n",
        "\n",
        "        print('Test predictions shape: {}'.format(y_pred_test.shape))\n",
        "\n",
        "        # Perform mask predictions binarization and RLEncoding. \n",
        "        y_test_pred_rle = {idx:\n",
        "                           rle_encode(y_pred_test[i] > confidence_threshold_best)\n",
        "                           for i, idx in enumerate(\n",
        "                               tqdm(self.test_df.index.values))}\n",
        "\n",
        "        return y_test_pred_rle\n",
        "\n",
        "    def generate_submission(self, y_test_pred_rle):\n",
        "        \n",
        "        \"\"\"\n",
        "        Submission generation based on encoded model predictions.\n",
        "        \n",
        "        # Arguments:\n",
        "            y_test_pred_rle: RLEncoded predictions.\n",
        "        # Returns:\n",
        "            submission: generated submission.\n",
        "        \"\"\"\n",
        "\n",
        "        submission = pd.DataFrame.from_dict(y_test_pred_rle, orient='index')\n",
        "        submission.index.names = ['id']\n",
        "        submission.columns = ['rle_mask']\n",
        "\n",
        "        return submission\n",
        "\n",
        "    def return_padding_borders(self):\n",
        "        \"\"\"\n",
        "        Return padding borders in case intermediate operations on original images\n",
        "        are needed.\n",
        "        \n",
        "        # Returns:\n",
        "            self.padding_pixels: tuple of padding borders.\n",
        "        \"\"\"\n",
        "        return self.padding_pixels\n",
        "\n",
        "    def __pad_image(self, img):\n",
        "        \n",
        "        \"\"\"\n",
        "        Helper function for images padding.\n",
        "        \n",
        "        # Arguments:\n",
        "            img: image as np.array\n",
        "            \n",
        "        # Returns:\n",
        "            img: padded image as np.array\n",
        "        \"\"\"\n",
        "\n",
        "        pad_floor = np.floor(\n",
        "            (np.asarray(self.image_size) - np.asarray(self.orig_image_size)) / 2)\n",
        "        pad_ceil = np.ceil((np.asarray(self.image_size) -\n",
        "                            np.asarray(self.orig_image_size)) / 2)\n",
        "\n",
        "        self.padding_pixels = np.asarray(\n",
        "            (pad_floor[0], pad_ceil[0], pad_floor[1], pad_ceil[1])).astype(np.int32)\n",
        "\n",
        "        y_min_pad, y_max_pad, x_min_pad, x_max_pad = self.padding_pixels[\n",
        "            0], self.padding_pixels[1], self.padding_pixels[2], self.padding_pixels[3]\n",
        "\n",
        "        img = cv2.copyMakeBorder(img, y_min_pad, y_max_pad,\n",
        "                                 x_min_pad, x_max_pad,\n",
        "                                 cv2.BORDER_REFLECT_101)\n",
        "\n",
        "        assert img.shape[:2] == self.image_size, '\\\n",
        "        Image after padding must have the same shape as input image.'\n",
        "\n",
        "        return img\n",
        "\n",
        "def rle_encode(im):\n",
        "    pixels = im.flatten(order='F')\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JAv53nGm4ILm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## data preparation"
      ]
    },
    {
      "metadata": {
        "id": "YQMP7bXa1Bve",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9c0b205-fdc8-4f31-8d22-077d4adfdc41"
      },
      "cell_type": "code",
      "source": [
        "# Input dictionary for SaltParser\n",
        "salt_parameters = {\n",
        "    'data_src': '',\n",
        "    'image_size': (128, 128),\n",
        "    'pad_images': False,\n",
        "    'grayscale': False,\n",
        "}\n",
        "\n",
        "salt_parser = SaltParser(**salt_parameters)\n",
        "\n",
        "normalize = True\n",
        "save = False\n",
        "\n",
        "\n",
        "# Automatic input_dim parameter specification\n",
        "# for model training.\n",
        "input_dim = salt_parameters['image_size']\n",
        "\n",
        "if salt_parameters['grayscale']:\n",
        "    input_dim = input_dim + (1,)\n",
        "else:\n",
        "    input_dim = input_dim + (3,)\n",
        "    \n",
        "# Run name\n",
        "run_name = '{}_grayscale{}_pad{}_size{}'.format(\n",
        "    'Unet',\n",
        "    int(salt_parameters['grayscale']),\n",
        "    int(salt_parameters['pad_images']),\n",
        "    input_dim[0])\n",
        "\n",
        "print('Run name: {}'.format(run_name))\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Run name: Unet_grayscale0_pad0_size128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "huZohnMv4jpY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "4ef78f41-68f5-431e-e229-5e9dce920e80"
      },
      "cell_type": "code",
      "source": [
        "salt_parser.initialize_data()\n",
        "X_train, y_train, X_test = salt_parser.load_data()\n",
        "\n",
        "\n",
        "\n",
        "train_df = salt_parser.compute_coverage()\n",
        "padding_pixels = salt_parser.return_padding_borders()\n",
        "\n",
        "\n",
        "#in order to not run out of memory\n",
        "del X_test\n",
        "gc.collect()\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  4%|▍         | 169/4000 [00:00<00:02, 1688.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading training set.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:02<00:00, 1622.43it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training set ready.\n",
            "X_train shape: (4000, 128, 128, 3)\n",
            "y_train shape: (4000, 128, 128, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/18000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "X_train - min: 0, max: 255\n",
            "y_train - min: 0, max: 255\n",
            "Loading test set.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18000/18000 [00:09<00:00, 1965.63it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set ready.\n",
            "X_test shape: (18000, 128, 128, 3)\n",
            "X_test - min: 0, max: 255\n",
            "Compute mask coverage for each observation.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "275"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "kLVcOf8v4a9k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "bc3343af-fe0b-40ba-d286-b0c0d5c76c1c"
      },
      "cell_type": "code",
      "source": [
        "if normalize:\n",
        "    # X_train, X_test = utils.normalize_along_channel(X_train, X_test)\n",
        "    X_train = X_train / 255.\n",
        "    y_train = y_train / 255.\n",
        "    #X_test = X_test / 255.\n",
        "    print('X_train - min: {}, max: {}'.format(np.min(X_train), np.max(X_train)))\n",
        "    print('y_train - min: {}, max: {}'.format(np.min(y_train), np.max(y_train)))\n",
        "    print('Train set: {}, {}'.format(X_train.shape, y_train.shape))\n",
        "    #print('X_test - min: {}, max: {}'.format(np.min(X_test), np.max(X_test)))\n",
        "    #print('Test set: {}'.format(X_test.shape))\n",
        "    \n",
        "X_train = X_train.astype(np.float32)\n",
        "y_train = y_train.astype(np.float32)\n",
        "#X_test = X_test.astype(np.float32)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train - min: 0.0, max: 1.0\n",
            "y_train - min: 0.0, max: 1.0\n",
            "Train set: (4000, 128, 128, 3), (4000, 128, 128, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6Iw2QnRY7iib",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "243847d6-5cfd-4706-ee17-67415e7c0527"
      },
      "cell_type": "code",
      "source": [
        "X_tr, X_val, y_tr, y_val, cov_train, cov_test, depth_train, depth_test = train_test_split(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    train_df.coverage.values,\n",
        "    train_df.z.values,\n",
        "    test_size=0.2, stratify=train_df.coverage_class, random_state=1234)\n",
        "\n",
        "\n",
        "del train_df\n",
        "gc.collect()\n",
        "\n",
        "del X_train, y_train\n",
        "gc.collect()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "9a5KW4P37wJM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lZihyZTn8qkK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}